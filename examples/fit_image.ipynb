{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# import cv2 # needed to create movie visualization of optimizaiton\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "# from tqdm import tqdm\n",
    "import imageio\n",
    "import torch\n",
    "import torch.distributions as dist\n",
    "\n",
    "from pybpl.library import Library\n",
    "from pybpl.model import CharacterModel\n",
    "from pybpl.objects.concept import CharacterType\n",
    "from pybpl.objects.part import StrokeType\n",
    "from pybpl.objects.relation import RelationIndependent, RelationAttachAlong\n",
    "from pybpl import rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library and type distribution\n",
    "lib = Library('../lib_data/')\n",
    "model = CharacterModel(lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for better image visualization in matplotlib\n",
    "def box_only(obj):\n",
    "    obj.tick_params(\n",
    "        which='both',\n",
    "        bottom=False,\n",
    "        left=False,\n",
    "        labelbottom=False,\n",
    "        labelleft=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## first, load the target image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_target = imageio.imread('./image_H.jpg')\n",
    "img_target = np.asarray(img_target, dtype=np.float32) / 255.\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(img_target, cmap='Greys')\n",
    "box_only(plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 105)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, create an initial \"H\" type and token that we will optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_H_type():\n",
    "    # first stroke has 1 sub-stroke, with id \"0\"\n",
    "    s1 = StrokeType(\n",
    "        nsub=torch.tensor(1), \n",
    "        ids=torch.tensor([0]),\n",
    "        shapes=lib.shape['mu'][0].view(5, 2, 1),\n",
    "        invscales=torch.tensor([0.5])\n",
    "    )\n",
    "    r1 = RelationIndependent(\n",
    "        category='unihist',\n",
    "        #gpos=torch.tensor([30., -22.]),\n",
    "        gpos=torch.tensor([32., -20.]),\n",
    "        xlim=lib.Spatial.xlim,\n",
    "        ylim=lib.Spatial.ylim,\n",
    "    )\n",
    "    # second stroke has 1 sub-stroke, with id \"9\"\n",
    "    s2 = StrokeType(\n",
    "        nsub=torch.tensor(1), \n",
    "        ids=torch.tensor([9]),\n",
    "        shapes=lib.shape['mu'][9].view(5, 2, 1),\n",
    "        invscales=torch.tensor([0.4])\n",
    "    )\n",
    "    r2 = RelationAttachAlong(\n",
    "        category='mid',\n",
    "        attach_ix=torch.tensor(0),\n",
    "        attach_subix=torch.tensor(0),\n",
    "        eval_spot=torch.tensor(4.5),\n",
    "        ncpt=lib.ncpt\n",
    "    )\n",
    "    # third stroke has 1 sub-stroke, with id \"0\"\n",
    "    s3 = StrokeType(\n",
    "        nsub=torch.tensor(1), \n",
    "        ids=torch.tensor([0]),\n",
    "        shapes=lib.shape['mu'][0].view(5, 2, 1),\n",
    "        invscales=torch.tensor([0.5])\n",
    "    )\n",
    "    r3 = RelationIndependent(\n",
    "        category='unihist',\n",
    "        #gpos=torch.tensor([70., -22.]),\n",
    "        gpos=torch.tensor([68., -20.]),\n",
    "        xlim=lib.Spatial.xlim,\n",
    "        ylim=lib.Spatial.ylim\n",
    "    )\n",
    "    k = torch.tensor(3)\n",
    "    P = [s1, s2, s3]\n",
    "    R = [r1, r2, r3]\n",
    "    # initialize the type\n",
    "    ctype = CharacterType(k, P, R)\n",
    "    \n",
    "    return ctype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2])\n",
      "torch.Size([35, 2])\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d16c0737c7f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mctype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_H_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mctoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# get optimizable parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mctoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlbs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mctoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlbs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/code/python/pyBPL/pybpl/model/model.py\u001b[0m in \u001b[0;36msample_token\u001b[0;34m(self, ctype)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscore_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/code/python/pyBPL/pybpl/model/token_dist.py\u001b[0m in \u001b[0;36msample_token\u001b[0;34m(self, ctype)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \"\"\"\n\u001b[1;32m    242\u001b[0m         \u001b[0;31m# sample part and relation tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mconcept_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCharacterTokenDist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;31m# sample affine warp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/code/python/pyBPL/pybpl/model/token_dist.py\u001b[0m in \u001b[0;36msample_token\u001b[0;34m(self, ctype)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mrtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_relation_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;31m# sample part position from relation token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mptoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;31m# append them to the list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mptoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data1/code/python/pyBPL/pybpl/model/token_dist.py\u001b[0m in \u001b[0;36msample_location\u001b[0;34m(self, rtoken, prev_parts)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mbase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attach_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_parts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ctype = initial_H_type()\n",
    "ctoken = model.sample_token(ctype)\n",
    "# get optimizable parameters\n",
    "params = ctype.parameters() + ctoken.parameters()\n",
    "lbs = ctype.lbs() + ctoken.lbs()\n",
    "ubs = ctype.ubs() + ctoken.ubs()\n",
    "# set requires_grad to True for asll parameters\n",
    "ctype.train()\n",
    "ctoken.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set large blur value to make learning easier\n",
    "ctoken.blur_sigma = torch.tensor(\n",
    "    10., dtype=torch.float, requires_grad=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pimg = model.get_pimg(ctoken)\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(pimg.detach().numpy(), cmap='Greys')\n",
    "box_only(plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vid = 'video.mov'\n",
    "if os.path.exists(vid):\n",
    "    os.remove(vid)\n",
    "video = cv2.VideoWriter(vid,-1,10,(105,105))\n",
    "nb_iter = 300\n",
    "interval = 5 # how often we will log pimg status\n",
    "lr = 4e-3\n",
    "img_target = torch.tensor(img_target)\n",
    "\n",
    "score_type_list = []\n",
    "score_token_list = []\n",
    "score_img_list = []\n",
    "optimizer = torch.optim.Adam(params, lr=lr)\n",
    "for idx in tqdm(range(nb_iter)):\n",
    "    if idx % interval == 0:\n",
    "        # store pimg at this iteration for later viewing\n",
    "        pimg = model.get_pimg(ctoken)\n",
    "        pimg = pimg.detach().numpy()\n",
    "        pimg = np.stack([pimg, pimg, pimg], axis=2)\n",
    "        pimg = np.asarray(pimg*255., dtype=np.uint8)\n",
    "        video.write(np.copy(pimg))\n",
    "    # compute scores\n",
    "    score_type = model.score_type(ctype)\n",
    "    score_token = model.score_token(ctype, ctoken)\n",
    "    score_img = model.score_image(ctoken, img_target)\n",
    "    score = score_type + score_token + score_img\n",
    "    # append to lists\n",
    "    score_type_list.append(score_type)\n",
    "    score_token_list.append(score_token)\n",
    "    score_img_list.append(score_img)\n",
    "    # first, zero all gradients\n",
    "    optimizer.zero_grad()\n",
    "    # now, perform backward pass\n",
    "    score_neg = -score\n",
    "    score_neg.backward()\n",
    "    # optimization step\n",
    "    optimizer.step()\n",
    "    # clip params at boundaries\n",
    "    with torch.no_grad():\n",
    "        for ip, param in enumerate(params):\n",
    "            lb = lbs[ip]\n",
    "            ub = ubs[ip]\n",
    "            if lb is not None:\n",
    "                torch.max(param, lb, out=param)\n",
    "            if ub is not None:\n",
    "                torch.min(param, ub, out=param)\n",
    "                \n",
    "cv2.destroyAllWindows()\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check loss vs iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14,5))\n",
    "# type and token scores\n",
    "axes[0].plot(score_type_list, c='b', label='log P(type)')\n",
    "axes[0].plot(score_token_list, c='g', label='log P(token | type)')\n",
    "axes[0].set_ylabel('log-likelihood')\n",
    "axes[0].set_xlabel('iteration')\n",
    "axes[0].legend()\n",
    "# image score\n",
    "axes[1].plot(score_img_list, c='r', label='log P(image | token)')\n",
    "axes[1].set_ylabel('log-likelihood')\n",
    "axes[1].set_xlabel('iteration')\n",
    "axes[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check pimg vs iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(img_target, cmap='Greys')\n",
    "box_only(plt)\n",
    "plt.title('target')\n",
    "plt.show()\n",
    "print('')\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=10, figsize=(15, 2))\n",
    "for i in range(10):\n",
    "    axes[i].imshow(imgs[i], cmap='Greys')\n",
    "    box_only(axes[i])\n",
    "    axes[i].set_title('%i' % (interval*i))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
